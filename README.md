NetLytics
=========
NetLytics is a Hadoop-powered framework for performing advanced analytics on various kinds of networks logs.

It is able to parse log files generated by popular network softwares implementing HTTP proxy, DNS server and passive sniffers; 
it can also parse raw PCAP files.

It assumes that log files are stored on HDFS in a Hadoop based cluster.

NetLytics uses log files to perform a wide range of advanced network analytics for traffic monitoring and security purposes. All code is written in Python and uses Apache Spark.

For information about this Readme file and this tool please write to
[martino.trevisan@polito.it](mailto:martino.trevisan@polito.it)

# 1. Prerequisites
Netlytics is designed to work in the Hadoop ecosystem. As such, it needs HDFS and Apache Spark to respectively store and process log files. It uses python 2.7 and few python packages: you can install them with pip
```
sudo pip install zipfile scapy numpy pandas pyasn
```
If you are using a cluster, these packages must be installed on each worker node.

You can clone the GitHub repository with the command:
```
git clone https://github.com/marty90/netlytics
```

# 2. Architecture
NetLytics is composed on many building blocks illustrated in the figure below.
![alt text](https://github.com/marty90/netlytics/raw/master/images/netlytics_arch.png)

## 2.1 Tools generating Network Logs
NetLytics handles log files generated by a wide number of softwares.
From raw log files, NetLytics can create Data Tables for **DNS**, **HTTP** and **Named Flows**.
Not all tables can be created from all tools.

|**Tool** | **DNS**  |  **HTTP**   |   **Named Flows** |
|-------|-----|------|-------------|
|  **Bro**   | Y   | Y    | Y           |
|  **Squid** | N   | Y    | Y           |
|  **Tstat**  | Y   | Y    | Y           |
| **Bind** | Y   | N    | N           |
|  **PCAP** | Y   | N    | N           |

It not differently specified, NetLytics assumes that the folder structure and the file names are the default ones.
Currently Netlytics can parse log files generated by 5 tools.
### Bro
[Bro](https://www.bro.org/) is a network security monitor that passively analyzes traffic and produces several log files.
In particular, log files for TCP, HTTP and DNS traffic are generated.
Bro typically rotate log files every hour, and puts all log files generated in one day in a separate directory. The typical directory tree is the following:
```
2017-11-20/
\------------ dns.22.00.00-23.00.00.log.gz
\------------ dns.23.00.00-00.00.00.log.gz
\------------ http.13.00.00-14.00.00.log.gz
\------------ http.14.00.00-15.00.00.log.gz
\------------ ...
2017-11-21/
\------------ ...
```
NetLyitics assumes that this directory structure is replicated in HDFS.

NetLytics Data Tables: **DNS**, **HTTP** and **Named Flows**.

### Squid
[Squid](http://www.squid-cache.org/) is the most popular software HTTP proxy. It generates a log file where all HTTP transactions are recorded. It is typically stored in `/var/log/squid/access.log`; it can assume various formats, but NetLytics assumes the default one is used (called `squid format` in Squid documentation).

Squid does not handle log file rotation and storage, but users typically employ the [logrotate](https://linux.die.net/man/8/logrotate) utility to handle this.
`logrotate` periodically rotates log files and stores old ones with the name `access.log-YYYYMMDD` where `YYYY`, `MM` and `DD` are the current year, month and day respectively.
NetLytics assumes this name format is used to store log files on HDFS.

NetLytics Data Tables: **HTTP** and **Named Flows**.


### Tstat
[Tstat](http://tstat.polito.it/) is a network meter that passively analyzes traffic and produces rich log files.
In particular, log files for TCP, HTTP and DNS traffic are generated.

Tstat typically rotate log files every hour, and puts all log files generated in one day in a separate directory. The typical directory tree is the following:
```
2016
\------------ 04-Apr
              \------------ 2017_04_01_00_30.out
              \------------ 2017_04_01_01_30.out
              \------------ 2017_04_01_02_30.out
              \------------ ...
\------------ 05-May
              \------------ 2017_05_01_00_30.out
              \------------ 2017_05_01_01_30.out
              \------------ ...
\------------ ...
2017
\------------ 01-Jan
...
```
NetLyitics assumes that this directory structure is replicated in HDFS.

NetLytics Data Tables: **DNS**, **HTTP** and **Named Flows**.

## 2.1 Data storage
NetLytics assumes that network log files are stored on HDFS and accessible by the current Spark user.
Each tool producing


### Bind
[Bind](https://www.isc.org/downloads/bind/) is the most popular software DNS server.
It can be configured to create log files changing the `/etc/bind/named.conf` files, adding:
```
logging {
  channel bind_log {
    file "/var/log/bind/bind.log" versions 3 size 5m;
    severity info;
    print-category yes;
    print-severity yes;
    print-time yes;
  };
  category queries { bind_log; };
};

```
The log file is created in `/var/log/bind/bind.log`.
Bind does not handle log file rotation and storage, but users typically employ the [logrotate](https://linux.die.net/man/8/logrotate) utility to handle this.
`logrotate` periodically rotates log files and stores old ones with the name `bind.log-YYYYMMDD` where `YYYY`, `MM` and `DD` are the current year, month and day respectively.
NetLytics assumes this name format is used to store log files on HDFS.

NetLytics Data Tables: **DNS**.

### Pcap Files
NetLytics can parse raw Pcap files to extract DNS data.
We reccommend to use the utility [dnscap](https://github.com/DNS-OARC/dnscap) to generate such Pcap files.
It can rotate log files after a configurable period of time.
Default Pcap file names have the format: `<base_name>.YYYYMMDD.HHmmSS.uSec`.
NetLytics assumes this format is used in HDFS.

NetLytics Data Tables: **DNS**.


## Connectors
The connectors are the software modules to parse log files and create Data Tables.
NetLytics parses log files on the original tool format, and creates on-the-fly Data Tables to be used by algorithms.

Each connector is identified by a *class name*, and is suited for generating a given *Data Table* from log file of a *tool*.

The following table illustrates the available connectors:

| **Tool**|**Data Table**| **Class Name**                                  |
|-------|------------|------------------------------------------------------|
| Tstat | DNS        | connectors.tstat_to_DNS.Tstat_To_DNS                 |
| Tstat | NamedFlows | connectors.tstat_to_named_flows.Tstat_To_Named_Flows |
| Tstat | HTTP       | connectors.tstat_to_HTTP.Tstat_To_HTTP               |
| Bro   | DNS        | connectors.bro_to_DNS.Bro_To_DNS                     |
| Bro   | HTTP       | connectors.bro_to_HTTP.Bro_To_HTTP                   |
| Bro   | NamedFlows | connectors.bro_to_named_flows.Bro_To_Named_Flows     |
| Squid | HTTP       | connectors.squid_to_HTTP.Squid_To_HTTP               |
| Squid | NamedFlows | connectors.squid_to_named_flows.Squid_To_Named_Flows |
| Bind  | DNS        | connectors.bind_to_DNS.Bind_To_DNS                   |
| PCAP  | DNS        | connectors.PCAP_to_DNS.PCAP_To_DNS                   |


## Data Tables
A Data Table represents a dataset of network measurements under a certain period of time. It is implemented using Spark Dataframes. Three types of Data Tables are handled by NetLytics:

* **DNS**: contains information about DNS traffic, such as queried domains, contacted resolvers, etc. It is generated by passive sniffers and DNS servers.

* **HTTP**: contains information HTTP transactions. It reports queried URLs, contacted servers, etc. It is generated by passive sniffers and HTTP servers. Limited information is available when encryption (SSL, TLS, HTTPS) is used.

* **Named Flows**: contains flow level measurements enriched with hostname of the server being contacted. Beside typical flow level statistics (number of packets and bytes), there is an explicit indication of the hostname of the server. This indication is typically generated using DPI on HTTP/TLS fields or with DNS traffic analysis. These logs are generated by passive sniffers and can be derived from HTTP proxy logs.








